{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfecdb9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    " %%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import json\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "st.set_page_config(page_title=\"KnowMap | Cross-Domain Knowledge Mapping\", layout=\"wide\")\n",
    "\n",
    "# USER DATABASE\n",
    "\n",
    "USER_DB = \"users.json\"\n",
    "if not os.path.exists(USER_DB):\n",
    "    with open(USER_DB, \"w\") as f:\n",
    "        json.dump({}, f)\n",
    "\n",
    "def load_users():\n",
    "    with open(USER_DB, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_users(data):\n",
    "    with open(USER_DB, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "# ROBUST CSV LOADER\n",
    "\n",
    "def load_dataframe(uploaded_file):\n",
    "    \"\"\"Auto-detect delimiter, handle missing headers, and name columns properly.\"\"\"\n",
    "    uploaded_file.seek(0)\n",
    "    try:\n",
    "        df = pd.read_csv(uploaded_file, sep=None, engine=\"python\", header=0)\n",
    "    except Exception:\n",
    "        uploaded_file.seek(0)\n",
    "        df = pd.read_csv(uploaded_file, sep=None, engine=\"python\", header=None)\n",
    "\n",
    "    lower_cols = [str(c).lower() for c in df.columns]\n",
    "    if not {\"entity_1\", \"relation\", \"entity_2\"}.issubset(set(lower_cols)):\n",
    "        if df.shape[1] >= 9:\n",
    "            df.columns = [\n",
    "                \"id\",\"entity_1\",\"relation\",\"entity_2\",\n",
    "                \"domain\",\"country\",\"start_year\",\"end_year\",\"notes\"\n",
    "            ]\n",
    "        elif df.shape[1] >= 3:\n",
    "            df.columns = [\"entity_1\",\"relation\",\"entity_2\"] + [\n",
    "                f\"col{i}\" for i in range(df.shape[1]-3)\n",
    "            ]\n",
    "    return df\n",
    "\n",
    "# HEADER\n",
    "\n",
    "st.markdown(\n",
    "    \"<h1 style='text-align:center; color:#FF7F50;'>KnowMap: Cross-Domain Knowledge Mapping</h1>\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "st.markdown(\"---\")\n",
    "\n",
    "tabs = st.tabs([\n",
    "    \"ğŸ  Welcome\",\n",
    "    \"ğŸ” Authentication\",\n",
    "    \"ğŸ“‚ Dataset Management\",\n",
    "    \"ğŸ§  NLP Extraction\",\n",
    "    \"ğŸŒ Semantic Search\",\n",
    "    \"ğŸ“Š Admin Dashboard\",\n",
    "    \"ğŸ’¬ Feedback\",\n",
    "])\n",
    "\n",
    "# HEADER\n",
    "\n",
    "st.markdown(\n",
    "    \"<h1 style='text-align:center; color:#FF7F50;'>KnowMap: Cross-Domain Knowledge Mapping</h1>\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "st.markdown(\"---\")\n",
    "\n",
    "tabs = st.tabs([\n",
    "    \"ğŸ  Welcome\",\n",
    "    \"ğŸ” Authentication\",\n",
    "    \"ğŸ“‚ Dataset Management\",\n",
    "    \"ğŸ§  NLP Extraction\",\n",
    "    \"ğŸŒ Semantic Search\",\n",
    "    \"ğŸ“Š Admin Dashboard\",\n",
    "    \"ğŸ’¬ Feedback\",\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
